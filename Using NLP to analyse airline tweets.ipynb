{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35227fed-7c19-4af8-98c9-0e4bfc5d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, itertools\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7020f88-fb26-4cf3-a244-9928bd608da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gs = \"C:\\\\Program Files\\\\gs\\\\gs10.03.1\\\\bin\"\n",
    "os.environ['PATH'] += os.pathsep + path_to_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f54f48-0b41-469a-a5b6-80b3a76d5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\New folder\\\\ML\\\\Tweets.csv\")\n",
    "df = df[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4ade85-4f6a-42b0-b5e1-caf8d20f7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(r\"([@])(\\w+)\\b\")\n",
    "AllReferences = map(lambda x: r.findall(x), df['text'])\n",
    "\n",
    "AllUniqueReferencesCombined = set(list(itertools.chain.from_iterable(AllReferences)))\n",
    "References = map(lambda x:x[0] + x[1], AllUniqueReferencesCombined)\n",
    "\n",
    "file = open(\"References.txt\", 'a')\n",
    "for each in References:\n",
    "    file.write(each+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f80736-8889-40eb-a1fb-ab4423b0d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNounPhrases(s):\n",
    "    try:\n",
    "        sentences = nltk.sent_tokenize(s)\n",
    "        sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "        sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    except:\n",
    "        return[]\n",
    "    else:\n",
    "        grammar = r\"NP:{<DT><NN|NNS|NNP|NNPS>*<NN|NNS|NNP|NNPS>}\"\n",
    "        cp = nltk.RegexpParser(grammar)\n",
    "        noun_phrases_list = [[''.join(leaf[0] for leaf in tree.leaves())\n",
    "                             for tree in cp.parse(sent).subtrees()\n",
    "                             if tree.label() == 'NP']\n",
    "                             for sent in sentences]\n",
    "        return noun_phrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a730bd3-9c0c-4538-b2e8-364b092f7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, sub in df.groupby('airline_sentiment'):\n",
    "    noun_phrases = map(lambda x:GetNounPhrases(x), sub['text'])\n",
    "    noun_phrases = list(itertools.chain.from_iterable(noun_phrases))\n",
    "    AllNounPhrases = set(list(itertools.chain.from_iterable(noun_phrases)))\n",
    "    filename = \"Noun Phrases for\" + str(group) + \"Review.txt\"\n",
    "    with open(filename, 'a', encoding='utf-8') as file:\n",
    "        for each in AllNounPhrases:\n",
    "            file.write(each + \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3fde7-ca57-4eda-9793-b75754b9565c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
